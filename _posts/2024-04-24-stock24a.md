---
title: Memory-Based Sequential Attention
abstract: Computational models of sequential attention often use recurrent neural
  networks, which may lead to information loss over accumulated glimpses and an inability
  to dynamically reweigh glimpses at each step. Addressing the former limitation should
  result in greater performance, while addressing the latter should enable greater
  interpretability. In this work, we propose a biologically-inspired model of sequential
  attention for image classification. Specifically, our algorithm contextualizes the
  history of observed locations from within an image to inform future gaze points,
  akin to scanpaths in the biological visual system. We achieve this by using a transformer-based
  memory module coupled with a reinforcement learning-based learning algorithm, improving
  both task performance and model interpretability. In addition to empirically evaluating
  our approach on classical vision tasks, we demonstrate the robustness of our algorithm
  to different initial locations in the image and provide interpretations of sampled
  locations from within the trajectory.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: stock24a
month: 0
tex_title: Memory-Based Sequential Attention
firstpage: 236
lastpage: 253
page: 236-253
order: 236
cycles: false
bibtex_author: Stock, Jason and Anderson, Charles
author:
- given: Jason
  family: Stock
- given: Charles
  family: Anderson
date: 2024-04-24
address:
container-title: Proceedings of The 2nd Gaze Meets ML workshop
volume: '226'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 4
  - 24
pdf: https://proceedings.mlr.press/v226/stock24a/stock24a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v226/stock24a/stock24a-supp.pdf
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
